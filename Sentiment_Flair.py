# -*- coding: utf-8 -*-
"""final_ML_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CudjVsIYI2JU6gvO7cp-akT1jlVrq0xh
"""

!pip install swifter
!pip install flair

import numpy as np
import pandas as pd
import re
from bs4 import BeautifulSoup
from html import unescape
import math
import csv


filename = r"/content/drive/MyDrive/machine_learning/UkraineCombinedTweetsDeduped_FEB27.csv.gzip"
data = pd.read_csv(filename, compression='gzip', index_col=0,encoding='utf-8', quoting=csv.QUOTE_ALL)


data.shape




oneFifth = math.ceil(len(data) * 0.01)



data = data[data["language"] == "en"].sample(oneFifth)

data.reset_index(drop=True, inplace=True)



data.shape





def remove_urls(z):
    cleaned_string = re.sub(r'(https|http)?:\/\/(\w|\.|\/|\?|\=|\&|\%)*\b', '', str(z), flags=re.MULTILINE)
    return cleaned_string



def unescape_stuff(z):
    soup = BeautifulSoup(unescape(z), 'lxml')
    return soup.text



def deEmojify(z):
    regrex_pattern = re.compile(pattern = "["
        u"\U0001F600-\U0001F64F"  # emoticons
        u"\U0001F300-\U0001F5FF"  # symbols & pictographs
        u"\U0001F680-\U0001F6FF"  # transport & map symbols
        u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                           "]+", flags = re.UNICODE)
    return regrex_pattern.sub(r'', z)



def unify_whitespaces(z):
    cleaned_string = re.sub(' +', ' ', z)
    return cleaned_string



def remove_symbols(z):
    cleaned_string = re.sub(r"[^a-zA-Z0-9?!.,]+", ' ', z)
    return cleaned_string



data['text'] = data['text'].str.lower()
data['text'] = data['text'].apply(remove_urls)
data['text'] = data['text'].apply(unescape_stuff)
data['text'] = data['text'].apply(deEmojify)
data['text'] = data['text'].apply(remove_symbols)
data['text'] = data['text'].apply(unify_whitespaces)



data['text'].head()




from flair.models import TextClassifier
from flair.data import Sentence

sia = TextClassifier.load('en-sentiment')


def flair_prediction(z):

    sentence = Sentence(z)

    try:
        sia.predict(sentence)
        score = sentence.labels[0]
        staging_score = str(score).replace("(",",").replace(")","")

        sentiment_score = staging_score.split(",")

        if "POSITIVE" in str(sentiment_score[0]):
            return "POSITIVE", float(sentiment_score[1].strip())
        elif "NEGATIVE" in str(sentiment_score[0]):
            return "NEGATIVE", float(sentiment_score[1].strip())
        else:
            return "NEUTRAL", 0.00
    except Exception:
        print(sentence)
        pass

    return "ERROR",0.00



data['Sentiment'] = ""
data['Sentiment_Score'] = np.nan



import swifter
data["Sentiment"],data["Sentiment_Score"] =  zip(*data["text"].swifter.apply(flair_prediction))



data.head().T

data.groupby(["Sentiment"]).agg({'Sentiment_Score': ['count','mean']})

from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report

label_encoder = LabelEncoder()


data['Sentiment_encoded'] = label_encoder.fit_transform(data['Sentiment'])


y = data['Sentiment_encoded']
X = data['Sentiment_Score'].values.reshape(-1, 1)


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


svm_classifier = SVC(kernel='linear')


svm_classifier.fit(X_train, y_train)


y_pred = svm_classifier.predict(X_test)

report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)
print(">>>>")
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

